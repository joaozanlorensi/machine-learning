{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This Notebook was based in the wonderful classes taught by Prof. Sebastian Raschka, which are all made available for free in his [YouTube Channel](https://www.youtube.com/watch?v=I8vRP4GVs_E)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Why Numpy? Why not staying strict to Python's default data types for multidimensional data? \n",
    "#### *(A practical, yet somehow detailed answer)*\n",
    "\n",
    "The short answer is: because using Numpy is much more efficient than using Python's default data types for manipulating lists of numeric values.    \n",
    "Numpy is written in [multiple programming languages](https://github.com/numpy/numpy), such as C and C++, and this allows it to be much more faster. \n",
    "While in Python's _lists every element acts like a pointer to a random position in memory and it allows users to store multiple different data types within the same variable, storing both the address and the element content in the background, Numpy uses contiguous blocks of memory, allowing our computer to do caching and for performing much faster lookup algorithms in RAM, with the restriction of using a single data type per variable.  \n",
    "As an example:  \n",
    "> Let's say you have 8 64-bit integers. Since you know the size that your array would have (512 bits), you would not have to store all of the memory addresses for all the elements in your array, but only the first one's address, and, from it, you would be able to find every other element with an efficient lookup algorithm.  \n",
    "\n",
    "Apart from the computational advantages, Numpy can also be more elegant and readable for performing vectorized operations and broadcasting.\n",
    "\n",
    "**Summing it up:** essentialy, you can and should use lists whenever you want to handle different data types within the same variable, when you have a smaller dataset or when you simply don't have a performance requirement. However, in scenarios where you need to manipulate a large amount of data, numeric data, and have a performance requirement, you should go for Numpy- it is the best choice for scientific computing, on most of the cases! "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Demonstration and performance comparison: Dot Product\n",
    "> A and B are n-dimensional vectors  \n",
    "> A's dimension: 1 x n  \n",
    "> B's dimension: 1 x n  \n",
    "> C = A . B = A \\* B^T = A1 \\* B1 + A2 \\* B2 + A3 \\* B3 + ... + An \\* Bn  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product using Lists\n",
    "def dot_product_list(A, B):\n",
    "    return sum([A[i] * B[i] for i in range(len(A))])\n",
    "\n",
    "# Dot product using Numpy\n",
    "def dot_product_numpy(A, B):\n",
    "    return np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining two big floating point lists and its respectives ndarrays\n",
    "A = [i/5.5 for i in range(1000000)]\n",
    "B = [i/8.8 for i in range(1000000)]\n",
    "A_numpy = np.array(A)\n",
    "B_numpy = np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "193 ms ± 3.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Measuring the time it takes for the dot product to be executed using Lists\n",
    "%timeit C = dot_product_list(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "686 µs ± 44.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Measuring the time it takes for the dot product to be executed using Numpy\n",
    "%timeit C_numpy = dot_product_numpy(A_numpy, B_numpy)"
   ]
  },
  {
   "source": [
    "The execution time speaks for itself! Numpy did much better in performance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exploring some nice Numpy features:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Custom Data Types:\n",
    "\n",
    "Numpy allows for custom data types, such as float16 or float32.  \n",
    "While this is a nice feature for adding more control over your data types, you must be careful because using less bits implies in less precision, and, in Scientific Computing, using higher precision data types, such as float64, is highly encouraged."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "type(A_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "type(A_numpy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_numpy = A_numpy.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.float16"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "type(A_numpy[0])"
   ]
  },
  {
   "source": [
    "### Useful ndarray attributes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "A_numpy.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "A_numpy.shape"
   ]
  },
  {
   "source": [
    "This and much more can be found at the [official Numpy documentation](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}